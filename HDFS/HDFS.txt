HDFS是一个分布式文件系统
namenode:
	1.管理HDFS的名称空间
	2.配置副本策略(一个文件可能有多个副本, 以应对文件损坏等情况)#一台服务器对于一个文件最多只有一个副本
	3.管理数据块映射信息
	4.处理客户端读写请求
datanode
	1.存储实际的数据块
	2.执行数据快的读写操作
client
	1.文件切分。文件上传HDFS的时候,client将文件切分成一个一个的Block,然后进行上传
	2.与namenode交互,读取文件的位置信息
	3.与datanode交互,读取或者写入数据
	4.client提供一些命令来管理HDFS,比如namenode格式化
	5.client可以通过一些命令来访问HDFS,比如对HDFS增删查改操作
secondarynamenode
	1.辅助namenode,分担其工作量
	2.在紧急情况下,可辅助其恢复

HDFS的文件块大小不能设置太小, 也不能太大.主要取决于磁盘传输速率.
	太小:会增加寻址时间
	太大:从磁盘传输数据的时间会明显大于定位这个块开始位置所需的时间
HDFS的shell操作
	前缀: hadoop fs
	创建文件
		hadoop fs -mkdir /文件名
	上传
		-moveFromLocal:从本地剪切粘贴到HDFS
		-copyFromLocal:从本地复制粘贴到HDFS
		-put:等同于copyFromLocal
		-appendToFile:追加一个文件到已经存在的文件末尾
	下载
		-copyToLocal:从HDFS拷贝到本地
		-get:等同于copyToLocal,可在拷贝时同时改名
	统计文件夹的大小信息
		-du -s -h:输出的两个字段中,第一个字段是文件的大小,第二个字段是文件的总大小(所有副本之和)
	修改HDFS中文件的副本数量
		-setrep 副本数
	其他查看,删除文件,修改文件权限等等都与Linux命令相同

HDFS的写数据流程
	1.客户端向NameNode请求上传文件,
	2.NameNode检查客户端权限, 检查目录结构, 然后响应可以上传文件
	3.客户端请求上传第一个block, 情返回DataNode
	4.NameNode返回多个DataNode节点,表示采用这些节点存储数据(副本)
	5.客户端请求DataNode建立传输通道, DataNode逐个向前应答
	6.传输数据
HDFS机架感知
	客户端在向NameNode发送上传数据请求时, NameNode选择与副本数相对应数量的节点.
	选择节点时, 假如存储3个副本, 第一个副本存储在客户端本地节点, 第二个副本则在另一个机架的随机一个节点
	第三个副本在第二个副本所在的机架的随机节点, 存储在不同机架是为了兼顾安全性, 存储在同一个机架则是为了兼顾性能.
HDFS的读数据流程
	1.客户端向NamNode请求下载文件
	2.NameNode检查客户端权限, 检查目录结构, 若都满足要求, 则返回目标文件的元数据
	3.客户端创建一个流来读取DataNode中的数据
	4.DataNode向客户端传输数据
	注意: 第3,4点中, 因为有多个节点存储相同的副本, 因此客户端将选择距离最近的节点传输.
	并且考虑节点的负载情况(若有多个客户端中的线程同时访问该节点则会导致该节点负载过高), 即负载过高则选择其他节点.
	读取过程是串行的, 即多个数据块是串行传输

NN和2NN工作机制
	在NameNode初始化后, hadoop目录/data/dfs/name/current目录下会产生fsImage,Edits等文件.
	fsImage(镜像文件)存储数据
		HDFS文件系统元数据的一个永久性的检查点, 其中包含HDFS文件系统的所有目录和文件inde的序列化信息.
	Edits(编辑日志)以追加的方式存储对数据的操作(如客户端发来的对数据增删改请求)并不计算结果
		存放HDFS文件系统的所有更新操作的路径, 文件系统客户端执行的所有写操作首先会被记录到Edits文件中.
	每次NameNode启动时, NN将fsImage与Edits整合(即对应Edits中的记录对fsImage中的数据进行修改),并将整合后的数据加载到内存
	2NN中定时执行CheckPoint操作,即将fsImage与Edits进行整合并且写入内存, 
	CheckPoint触发条件:1.定时时间到, Edits中的数据满了
	查看fsImage文件
		hdfs oiv -p 转换为什么文件类型(XML) -i 镜像文件 -o 输出路径
	查看Edits文件
		hdfs oev 同查看fsImage
DataNode工作机制
	DataNode启动时, 主动向NameNode汇报block信息, 
	NameNode记录下来汇报过的DataNode, 认为其是可工作的.
	每隔3秒钟, DataNode向NameNode发送"心跳", 若NameNode较长时间没有收到DataNode心跳,
	则认为该DataNode损坏, NameNode不会再安排客户端与该DataNode有相互的读写交互.
	每隔6小时, DataNode向NameNode汇报当前解读信息(扫描自己的节点块信息).
	