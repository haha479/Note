安装jdk8.0
	下载jar包(jdk-8u144-linux-x64.tar.gz)
	解压至目录/opt/module/下
	tar -zxvf jdk-8u144-linux-x64.tar.gz -C /opt/module

	添加环境变量
	在/etc/profile.d/目录下新建存放环境变量的.sh文件
	vi /etc/profile.d/my_env.sh
	添加内容
	#JAVA_HOME
	export JAVA_HOME=/opt/module/jdk1.8.0_144
	export PATH=$PATH:$JAVA_HOME/bin
	使脚本重新生效
	source /etc/profile
安装hadoop3.1.3
	下载hadoop源码包(hadoop-3.1.3.tar.gz)
	解压至目录/opt/module/下
	tar -zxvf hadoop-3.1.3.tar.gz -C /opt/module

	添加环境变量
	修改/etc/profile.d/my_env.sh文件(安装jdk时已创建的文件)
	vi /etc/profile.d/my_env.sh
	添加内容
	#HADOOP_HOME
	export HADOOP_HOME=/opt/module/hadoop-3.1.3
	export PATH=$PATH:$HADOOP_HOME/bin
	export PATH=$PATH:$HADOOP_HOME/sbin
	使脚本重新生效
	source /etc/profile
hadoop运行模式
	本地运行模式：数据存储在本地
	伪分布式：数据存储在HDFS
	完全分布式：多台真实存在的服务器工作，并且数据存储在HDFS

本地运行模式官方wordcount案例(统计一个文件中每个词出现的次数)
	hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount wcinput/ wcoutput
	//wcinput为输入目录, 该目录中有待统计的文件, wcoutput为输出目录, 该目录事先不能存在
	//...examples-3.1...为官方工具, wordcount为统计的命令

起集群
	配置文件etc/hadoop/core-site.xml, hdfs-site.xml, mapred-site.xml, yarn-site.xml
	格式化namenode
		格式化会产生新的集群id,如果是重新格式化namenode,要先停止namenode和datanode进程,
		并且删除所有机器的data和logs目录
		hdfs namenode -format
	启动HDFS
		sbin/start-dfs.sh
	在配置了ResourceManager的节点上启动YARN
		sbin/start-yarn.sh
	在workers文件配置工作节点
		在以下文件中添加集群服务器地址(不要有多余空行和换行)
		hadoop/etc/hadoop/workers
	jps可查看启动的组件进程
对于HDFS, yarn的启动, 在sbin文件中都有脚本文件可以运行
启动历史服务器
	配置mapred-site.xml文件, 配置指定历史服务器端地址和历史服务器web端地址
	开启历史服务器
		mapred --daemon start historyserver
服务组件逐一启动或停止
	HDFS组件
		hdfs --daemon start/stop namenode/datanode/secondarynamenode
	YARN
		yarn --daemon start/stop resourcemanager/nodemanager
HDFS操作
	创建文件
		hadoop fs -mkdir /文件名
	上传文件
		hadoop fs -put 本地文件路径 hdfs文件系统路径
配置日志的聚集
	#将所有集群服务器的日志聚集到HDFS, 方便用户查看
	配置yarn-site.xml文件
	重启yarn, history服务器

