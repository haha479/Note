Hive概念
	Hive本质是一个Hadoop客户端,用于将HQL(Hive SQL)转化成MapReduce程序
	1.Hive中每张表的数据存储在HDFS
	2.Hive分析数据底层的实现是MapReduce(也可配置为Spark或Tez)
	3.执行程序运行在Yarn上
	4.Hive将元数据存储在数据库中

配置Hive元数据存储到mysql
	1.mysql中创建数据库metastore
	2.拷贝mysql-connector-java-...jar至hive/lib
	3.删除原有的元数据库derby产生的数据,在hive/metastore_db(初始化时指定的数据库)
	4.配置conf/hive-site.xml文件(需新建)
	5.初始化源数据库
		bin/schematool -dbType mysql -initSchema -verbose

hiveserver2
	Hive的hiveserver2服务的作用时提供jdbc/odbc接口,为用户提供远程访问Hive数据的功能.
	部署:
	1.配置hadoop中core-site.xml并分发给集群所有节点
	2.配置hive中hive-site.xml
	3.启动hiveserver2
		nohup hive --service hiveserver2 1>/dev/null 2>&1 &    #非阻塞运行

	测试:
		使用hive中自带客户端beeline测试连接
		在任一节点中使用beeline测试连接
			beeline -u jdbc:hive2://hadoop102:10000 -n self479

metastore服务
	hive的metastore服务的作用是为Hive CLI或Hiveserver2提供元数据访问接口,无需为每个客户端配置元数据库身份验证(不负责存储元数据)
	metastore默认为嵌入式,即metastore嵌入在客户端中, 需要在客户端配置jdbc4个参数.
	metastore独立服务模式
		Hive CLI或Hiveserver2通过metastore访问元数据库
	配置
		metastore服务端配置hive-site.xml文件(一台计划节点配置), 内容为jdbc连接的URL,Driver,Usernmane,Password
		启动metastore服务
			nohup hive --service metastore &
		metastore客户端配置hive-site.xml文件, 内容为指定metastore服务的地址与端口号
