mapReduce是分布式的计算框架

mapReduce编程规范
	用户编写的程序分成三个部分: Mapper, Reducer, Driver
	在mapper中用户编写将数据处理的逻辑代码;
	在reducer中接收mapper输出并排序等处理后的数据后, 编写逻辑进行对数据的运算;
	Driver中关联mapper和reducer, 设置map和最终输出的KV类型

mapReduce运行过程
	大概执行顺序:Mapper->Reducer->Driver
	mapper从输入文件中获取一行(TextInputFormat)作为value, key为偏移量, 每处理一行调用一次map()方法,
	map()中处理之后, reducer从mapper中拉取KV数据.
	从map方法之后到reduce方法之前, 数据通过key进行了整理(shuffle), 即按照key排序并且数据按顺序进入reducer依次处理,
	进入reducer的数据key即为mapper中输出的key, value为一个容器, 其中存放了mapper中输出的value, 
	若key相同,则该容器中有多个值(整合:也属于shuffle过程之中)

数据切片与MapTask并行度决定机制
	数据切片只是在逻辑上对输入进行分片,其是MapReduce程序计算输入数据的单位.
	1. 一个Job的Map阶段并行度由客户端在提交Job时的切片数决定
	2. 每一个Split切片分配一个MapTask并行实例处理
	3. 默认情况下, 切片大小=BlockSize
	4. 切片时不考虑数据集整体, 而是逐个针对每一个文件单独切片

切片底层流程
	1. 程序先找到你数据存储的目录
	2. 开始遍历处理(规划切片)目录下的每一个文件
	3. 遍历第一个文件
		3.1 获取文件大小fs.sizeOf(文件)
		3.2 计算切片大小
			Math.max(minSize, Math.min(maxSize, blockSize))
		3.3 默认情况下, 切片大小=blocksize
		3.4 开始切片, 每次切片时, 都要判断当前剩余的部分是否大于块的1.1倍, 不大于就划分一块切片
		3.5 将切片信息写到一个切片规划文件中
		3.6 整个切片的核心过程在getSplit()中完成
		3.7 InputSplit只记录了切片的元数据信息, 比如起始位置,长度以及所在的节点列表等
	4. 提交切片规划文件到YARN上, YARN上的MrAppMaster就可以根据切片规划文件计算开启MapTask个数
CombineTextInputFormat切片机制
	CombineTextInputFormat用于小文件过多的场景, 它可以将多个小文件从逻辑上规划到一个切片中, 将多个小文件交给一个MapTask处理.
序列化与反序列化
	将内存中的对象转换为字节码的过程称为序列化, 相反的过程即为反序列化