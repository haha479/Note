mapReduce是分布式的计算框架

mapReduce编程规范
	用户编写的程序分成三个部分: Mapper, Reducer, Driver
	在mapper中用户编写将数据处理的逻辑代码;
	在reducer中接收mapper输出并排序等处理后的数据后, 编写逻辑进行对数据的运算;
	Driver中关联mapper和reducer, 设置map和最终输出的KV类型

mapReduce运行过程
	大概执行顺序:Mapper->Reducer->Driver
	mapper从输入文件中获取一行(TextInputFormat)作为value, key为偏移量, 每处理一行调用一次map()方法,
	map()中处理之后, reducer从mapper中拉取KV数据.
	从map方法之后到reduce方法之前, 数据通过key进行了整理(shuffle), 即按照key排序并且数据按顺序进入reducer依次处理,
	进入reducer的数据key即为mapper中输出的key, value为一个容器, 其中存放了mapper中输出的value, 
	若key相同,则该容器中有多个值(整合:也属于shuffle过程之中)

数据切片与MapTask并行度决定机制
	数据切片只是在逻辑上对输入进行分片,其是MapReduce程序计算输入数据的单位.
	1. 一个Job的Map阶段并行度由客户端在提交Job时的切片数决定
	2. 每一个Split切片分配一个MapTask并行实例处理
	3. 默认情况下, 切片大小=BlockSize
	4. 切片时不考虑数据集整体, 而是逐个针对每一个文件单独切片(TextInputFormat)

切片底层流程
	1. 程序先找到你数据存储的目录
	2. 开始遍历处理(规划切片)目录下的每一个文件
	3. 遍历第一个文件
		3.1 获取文件大小fs.sizeOf(文件)
		3.2 计算切片大小
			Math.max(minSize, Math.min(maxSize, blockSize))
		3.3 默认情况下, 切片大小=blocksize
		3.4 开始切片, 每次切片时, 都要判断当前剩余的部分是否大于块的1.1倍, 不大于就划分一块切片
		3.5 将切片信息写到一个切片规划文件中
		3.6 整个切片的核心过程在getSplit()中完成
		3.7 InputSplit只记录了切片的元数据信息, 比如起始位置,长度以及所在的节点列表等
	4. 提交切片规划文件到YARN上, YARN上的MrAppMaster就可以根据切片规划文件计算开启MapTask个数
CombineTextInputFormat切片机制
	CombineTextInputFormat用于小文件过多的场景, 它可以将多个小文件从逻辑上规划到一个切片中, 将多个小文件交给一个MapTask处理.
	CombineTextInputFormat读取数据的方式和TextInputFormat一样,也是按行读取,key为偏移量,value为一行字符.
	该机制包括以下两个过程
	1 虚拟存储过程
	1.1 将输入目录下所有文件大小, 依次和设置的 setMaxInputSplitSize 值比较, 如果不大于设置的最大值, 逻辑上划分一个块.
	1.2 如果输入文件大于设置的最大值且大于两倍, 那么以最大值切割一块, 当剩余数据大小超过设置的最大值且不大于最大值2倍, 此时将文件均分成2个虚拟存储块(防止出现太小切片).
		1.7M < 4M 划分一块
		5.1M > 4M 但是小于 2*4M 划分二块：块1=2.55M, 块2=2.55M
		3.4M < 4M 划分一块
		6.8M > 4M 但是小于 2*4M 划分二块：块1=3.4M, 块2=3.4M
	最终存储的文件：
		1.7M
		2.55M, 2.55M
		3.4M
		3.4M, 3.4M

	2 切片过程
	2.1 判断虚拟存储的文件大小是否大于 setlMaxIputSplitSize 值, 大于等于则单独形成一个切片.
	2.2 如果不大于则跟下一个虚拟存储文件进行合并, 共同形成一个切片.
	最终会形成3个切片:
		1.7+2.55 M, 2.55+3.4 M, 34+3.4 M
序列化与反序列化
	将内存中的对象转换为字节码的过程称为序列化, 相反的过程即为反序列化

关于MapReduce中的分区
	环形缓冲区写出的数据会进行分区, 不同分区的数据进入到不同的reduce
	一个maptask会产生多个分区,并对分区编号, reducetask从多个maptask中拉取相同编号分区的数据.
	reducetask将数据处理之后通过OutPutFormat格式输出到文件(一个reducetask输出一个结果文件).
	代码实现中的分区结果
		如果ReduceTask的数量>getPartition的结果数, 则会产生几个空的输出文件part-r-000xx.
		如果1<ReduceTask的数量<getPartition的结果数, 则有一部分分区数据无处安防, 会报I/O错误.
		如果ReduceTask的数量=1, 则不管MapTask端输出多少个分区文件, 最终结果都交给这一个ReduceTask, 最终只产生一个结果文件part-r-00000.
		分区号必须从零开始, 逐一累加.
排序
	MapTask和ReduceTask均会对数据按照key排序, 该操作属于Hadoop的默认行为.

合并
	Combiner是MR程序中Mapper和Reducer之外的一种组件(即非默认).
	Combiner组件的父类就是Reducer.
	Combiner和Reducer的区别在于运行的位置.
		Combiner是在每一个MapTask所在的节点运行.
		Reducer是接收全局所有Mapper的输出结果.
	combiner的意义就是对每一个MapTask的输出进行局部汇总, 以减小网络传输量.
	Combiner的输出kv应该跟Reducer的输入kv对应起来
	